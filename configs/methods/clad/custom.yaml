lr: 1.e-3
optimizer: sgd
beta: 0.9
weight_decay: 0.
steps: 1
nesterov: false

# -- my modifications --:

update_method: emateacher # source_pseudolabels | emateacher

## distillation
distillation_out_temp: 1 # of ditillation loss of output
features_distillation_weight: 0 # distillation on feature level weight with respect to loss

## exemplars
memory_size: 10
num_replay_samples: 10
replay_augs: mixup_from_memory # null | cotta | mixup_from_memory | mixup_within_memory

num_first_blocks_for_update: -1

fisher_size: 2000
choose_params_with_fisher: false

## ema teacher
mt: 0.999

## sample choosing for update
sampling_method: null # null | stochastic_entropy | random | eata | eata_weight | stochastic_entropy_reverse | stochastic_entropy_weight

## dynamic bn:
bn_dist_scale: 0.1
init_beta: 0.1
smoothing_beta: 0.2
