lr: 0.00025
optimizer: sgd
beta: 0.9
weight_decay: 0.
steps: 1
nesterov: false

## exemplars
memory_size: 2000

# ema teacher
mt: 0.999

bn_dist_scale: 0.1
init_beta: 0.1
smoothing_beta: 0.2

alpha: 0.4
